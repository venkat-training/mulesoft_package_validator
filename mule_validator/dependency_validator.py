import os
import xml.etree.ElementTree as ET
import logging
import re
import subprocess
from mule_validator.security_patterns import (
    PASSWORD_KEYWORDS,
    COMMON_PASSWORD_PATTERNS,
    GENERIC_SECRET_KEYWORDS,
    GENERIC_SECRET_VALUE_PATTERNS
)

# Configure logging
logger = logging.getLogger(__name__)

"""
Validates Maven POM files and project dependencies for MuleSoft projects.

This module provides functionalities to:
- Parse `pom.xml` files to extract declared dependencies.
- Scan `pom.xml` for hardcoded secrets (passwords, generic keys) in tags, text, and attributes.
- Identify duplicate dependency declarations.
- Check if dependency JARs are present in the local build target directory or Maven repository.
- Attempt to resolve dependencies using Maven to verify they can be downloaded.
- Scan Mule configuration files for naive evidence of dependency usage (known limitations apply).
- Calculate the size of the build output directory.

Known Limitations:
- `scan_code_for_dependencies`: Uses simple string matching, which can lead to false positives/negatives.
  It does not perform deep code analysis to confirm actual Java class usage from dependencies.
- `check_dependency_resolution`: May rely on a hardcoded path to the Maven executable
  and requires Maven to be installed and configured correctly on the system running the validator.
"""

# Define constants
MAVEN_POM_NAMESPACE = "http://maven.apache.org/POM/4.0.0"

# Pre-compile regexes and prepare keywords
COMPILED_COMMON_PASSWORD_PATTERNS = [re.compile(p, re.IGNORECASE) for p in COMMON_PASSWORD_PATTERNS]
COMPILED_GENERIC_SECRET_VALUE_PATTERNS = [re.compile(p, re.IGNORECASE) for p in GENERIC_SECRET_VALUE_PATTERNS]
LOWERCASE_PASSWORD_KEYWORDS = [k.lower() for k in PASSWORD_KEYWORDS]
LOWERCASE_GENERIC_SECRET_KEYWORDS = [k.lower() for k in GENERIC_SECRET_KEYWORDS]


def get_element_path(element):
    """
    Generates a simplified path for an XML element, primarily its tag name,
    with the namespace removed for brevity.

    This is a helper function, typically used for creating more readable paths
    in issue reports generated by `find_secrets_in_pom_xml`.

    Args:
        element (xml.etree.ElementTree.Element | None): The XML element.

    Returns:
        str: A string representing the simplified path (tag name) of the element,
             or "UnknownElement" if the input element is None.
    """
    if element is None:
        return "UnknownElement"
    tag_name = element.tag
    if '}' in tag_name:
        tag_name = tag_name.split('}', 1)[-1]
    return tag_name


def find_secrets_in_pom_xml(root, pom_file_path):
    """
    Traverses the XML tree of a parsed POM file (`pom.xml`) and checks for
    hardcoded secrets in element tags, text content, and attribute names/values.

    It uses predefined lists of keywords (e.g., "password", "secret") and
    regex patterns to identify potential secrets.

    Args:
        root (xml.etree.ElementTree.Element | None): The root element of the
            parsed POM XML tree.
        pom_file_path (str): The path to the POM file, used for reporting.

    Returns:
        list[dict]: A list of dictionaries, where each dictionary represents a
        found issue. Each dictionary contains:
            - 'file_path' (str): Path to the POM file.
            - 'xml_path' (str): Simplified XML path (tag name) where the issue was found.
            - 'element_tag' (str): Full tag of the element.
            - 'attribute_name' (str | None): Name of the attribute if the issue is in an attribute, else None.
            - 'value_excerpt' (str): An excerpt of the suspicious value.
            - 'issue_type' (str): Type of issue (e.g., 'Hardcoded Secret', 'Suspicious Value').
            - 'message' (str): A descriptive message about the issue.
    """
    issues = []
    if root is None:
        return issues

    for element in root.iter():
        element_tag_for_path = get_element_path(element)
        element_tag_lower = element_tag_for_path.lower()

        # 1. Check element tag name
        if element_tag_lower in LOWERCASE_PASSWORD_KEYWORDS and element.text:
            issues.append({
                'file_path': pom_file_path, 'xml_path': element_tag_for_path, 'element_tag': element.tag,
                'attribute_name': None, 'value_excerpt': (element.text or "")[:50] + ('...' if len(element.text or "") > 50 else ''),
                'issue_type': 'Hardcoded Secret',
                'message': f"Element tag <{element_tag_for_path}> matches a password keyword and contains text."
            })
        elif element_tag_lower in LOWERCASE_GENERIC_SECRET_KEYWORDS and element.text:
            issues.append({
                'file_path': pom_file_path, 'xml_path': element_tag_for_path, 'element_tag': element.tag,
                'attribute_name': None, 'value_excerpt': (element.text or "")[:50] + ('...' if len(element.text or "") > 50 else ''),
                'issue_type': 'Hardcoded Secret',
                'message': f"Element tag <{element_tag_for_path}> matches a generic secret keyword and contains text."
            })

        # 2. Check element text content
        if element.text and isinstance(element.text, str):
            text_value = element.text.strip()
            if not text_value:
                continue
            for pattern_obj in COMPILED_COMMON_PASSWORD_PATTERNS:
                if pattern_obj.search(text_value):
                    issues.append({
                        'file_path': pom_file_path, 'xml_path': element_tag_for_path, 'element_tag': element.tag,
                        'attribute_name': None, 'value_excerpt': text_value[:50] + ('...' if len(text_value) > 50 else ''),
                        'issue_type': 'Suspicious Value',
                        'message': f"Text content of <{element_tag_for_path}> matches common password pattern: {pattern_obj.pattern}"
                    })
            for pattern_obj in COMPILED_GENERIC_SECRET_VALUE_PATTERNS:
                if pattern_obj.search(text_value):
                    issues.append({
                        'file_path': pom_file_path, 'xml_path': element_tag_for_path, 'element_tag': element.tag,
                        'attribute_name': None, 'value_excerpt': text_value[:50] + ('...' if len(text_value) > 50 else ''),
                        'issue_type': 'Suspicious Value',
                        'message': f"Text content of <{element_tag_for_path}> matches generic secret pattern: {pattern_obj.pattern}"
                    })

        # 3. Check attributes
        for attr_name, attr_value in element.attrib.items():
            attr_name_lower = attr_name.lower()
            if isinstance(attr_value, str):
                if attr_name_lower in LOWERCASE_PASSWORD_KEYWORDS:
                    issues.append({
                        'file_path': pom_file_path, 'xml_path': element_tag_for_path, 'element_tag': element.tag,
                        'attribute_name': attr_name, 'value_excerpt': attr_value[:50] + ('...' if len(attr_value) > 50 else ''),
                        'issue_type': 'Hardcoded Secret',
                        'message': f"Attribute '{attr_name}' in <{element_tag_for_path}> matches a password keyword."
                    })
                elif attr_name_lower in LOWERCASE_GENERIC_SECRET_KEYWORDS:
                    issues.append({
                        'file_path': pom_file_path, 'xml_path': element_tag_for_path, 'element_tag': element.tag,
                        'attribute_name': attr_name, 'value_excerpt': attr_value[:50] + ('...' if len(attr_value) > 50 else ''),
                        'issue_type': 'Hardcoded Secret',
                        'message': f"Attribute '{attr_name}' in <{element_tag_for_path}> matches a generic secret keyword."
                    })

                for pattern_obj in COMPILED_COMMON_PASSWORD_PATTERNS:
                    if pattern_obj.search(attr_value):
                        issues.append({
                            'file_path': pom_file_path, 'xml_path': element_tag_for_path, 'element_tag': element.tag,
                            'attribute_name': attr_name, 'value_excerpt': attr_value[:50] + ('...' if len(attr_value) > 50 else ''),
                            'issue_type': 'Suspicious Value',
                            'message': f"Value of attribute '{attr_name}' in <{element_tag_for_path}> matches common password pattern: {pattern_obj.pattern}"
                        })
                for pattern_obj in COMPILED_GENERIC_SECRET_VALUE_PATTERNS:
                    if pattern_obj.search(attr_value):
                        issues.append({
                            'file_path': pom_file_path, 'xml_path': element_tag_for_path, 'element_tag': element.tag,
                            'attribute_name': attr_name, 'value_excerpt': attr_value[:50] + ('...' if len(attr_value) > 50 else ''),
                            'issue_type': 'Suspicious Value',
                            'message': f"Value of attribute '{attr_name}' in <{element_tag_for_path}> matches generic secret pattern: {pattern_obj.pattern}"
                        })
    return issues


def parse_pom_dependencies(pom_file_path):
    """
    Parses a Maven POM file (`pom.xml`) to extract dependency information.

    Args:
        pom_file_path (str): The path to the `pom.xml` file.

    Returns:
        list[tuple[str, str, str | None, str | None, str]]: A list of tuples,
        where each tuple represents a dependency and contains:
            - groupId (str)
            - artifactId (str)
            - version (str | None): None if version is not specified.
            - classifier (str | None): None if classifier is not specified.
            - type (str): Defaults to "jar" if not specified.
    """
    dependencies = []
    try:
        tree = ET.parse(pom_file_path)
        root = tree.getroot()
        for dependency in root.findall(f".//{{{MAVEN_POM_NAMESPACE}}}dependency"):
            group_id = dependency.find(f"{{{MAVEN_POM_NAMESPACE}}}groupId")
            artifact_id = dependency.find(f"{{{MAVEN_POM_NAMESPACE}}}artifactId")
            version = dependency.find(f"{{{MAVEN_POM_NAMESPACE}}}version")
            classifier = dependency.find(f"{{{MAVEN_POM_NAMESPACE}}}classifier")
            dep_type = dependency.find(f"{{{MAVEN_POM_NAMESPACE}}}type")
            if group_id is not None and artifact_id is not None:
                dependencies.append((
                    group_id.text.strip(),
                    artifact_id.text.strip(),
                    version.text.strip() if version is not None and version.text else None,
                    classifier.text.strip() if classifier is not None and classifier.text else None,
                    dep_type.text.strip() if dep_type is not None and dep_type.text else "jar"
                ))
    except Exception as e:
        logger.error(f"Error parsing {pom_file_path}: {e}")
    return dependencies

def scan_code_for_dependencies(package_folder_path, dependencies):
    """
    Scans MuleSoft XML configuration files within a package for text-based evidence
    of dependency usage.

    This function performs a simple string search for the `groupId` or `artifactId`
    of each dependency within the content of `.xml` files.

    Known Limitations:
        - This method is a naive check and can lead to false positives (e.g., if an
          `artifactId` is a common word found in comments or unrelated text) or
          false negatives (if a dependency is used via Java code compiled into
          classes and not directly referenced by its coordinates in XML).
        - It does not understand the context of Mule configurations or Java class usage.

    Args:
        package_folder_path (str): The path to the root of the MuleSoft package folder.
        dependencies (list[tuple[str, str, str | None, str | None, str]]):
            A list of dependency tuples (groupId, artifactId, version, classifier, type),
            typically obtained from `parse_pom_dependencies`.

    Returns:
        set[tuple[str, str, str | None, str | None, str]]: A set of dependency tuples
        that were found (by string matching) in the scanned XML files.
    """
    used_dependencies = set()
    if not dependencies:
        return used_dependencies

    for root_dir, _, files in os.walk(package_folder_path):
        for file in files:
            if file.endswith('.xml'):
                file_path = os.path.join(root_dir, file)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        for dep in dependencies:
                            group_id, artifact_id = dep[0], dep[1]
                            if group_id in content or artifact_id in content:
                                used_dependencies.add(dep)
                except (IOError, OSError) as e:
                    logger.error(f"Error reading or processing file: {file_path} - {e}")
    return used_dependencies

def calculate_build_size(build_folder_path):
    """
    Calculates the total size of all files within a given directory and its subdirectories.

    Args:
        build_folder_path (str): The path to the directory whose size is to be calculated
                                 (e.g., the `target` folder of a Maven project).

    Returns:
        int: Total size of the directory content in bytes. Returns 0 if the
             directory does not exist or is not accessible.
    """
    total_size = 0
    if not os.path.isdir(build_folder_path):
        logger.warning(f"Build folder path {build_folder_path} does not exist or is not a directory.")
        return total_size
    for dirpath, _, filenames in os.walk(build_folder_path):
        for filename in filenames:
            file_path = os.path.join(dirpath, filename)
            total_size += os.path.getsize(file_path)
    return total_size

def check_dependency_jars(target_folder, dependencies):
    """
    Checks if dependency artifacts (JARs, ZIPs, etc.) are present in the specified
    `target_folder` (typically the project's build output directory, e.g., `target/`)
    or in the local Maven repository (`~/.m2/repository`).

    The function constructs expected artifact names based on groupId, artifactId,
    version, classifier, and type.

    Args:
        target_folder (str): The path to the project's target/build directory.
        dependencies (list[tuple[str, str, str | None, str | None, str]]):
            A list of dependency tuples.

    Returns:
        list[str]: A list of artifact names (e.g., "my-artifact-1.0.0.jar") that
                   were not found in either the `target_folder` or the local
                   Maven repository.
    """
    missing_artifacts = []
    m2_repo = os.path.expanduser("~/.m2/repository")
    for group_id, artifact_id, version, classifier, dep_type in dependencies:
        if not version:
            continue
        ext = dep_type if dep_type != "jar" else "jar"
        if classifier:
            artifact_name = f"{artifact_id}-{version}-{classifier}.{ext}"
        else:
            artifact_name = f"{artifact_id}-{version}.{ext}"
        found = False
        # Check in target folder
        for root, dirs, files in os.walk(target_folder):
            if artifact_name in files:
                found = True
                break
        # Check in local Maven repository
        if not found:
            group_path = os.path.join(m2_repo, *group_id.split('.'), artifact_id, version)
            artifact_path = os.path.join(group_path, artifact_name)
            if os.path.isfile(artifact_path):
                found = True
        if not found:
            missing_artifacts.append(artifact_name)
    return missing_artifacts

def check_dependency_resolution(group_id, artifact_id, version, classifier=None, dep_type="jar"):
    """
    Checks if a specific Maven dependency is resolvable.

    It first attempts to find the dependency artifact in the local Maven repository
    (`~/.m2/repository`). If not found locally, it tries to resolve the dependency
    by invoking a Maven command (`mvn dependency:get`).

    Uses the correct file extension based on the dependency type (e.g., ".jar", ".zip").

    Note:
        This function may rely on a hardcoded path to the Maven executable
        (e.g., `r"C:\apps\apache-maven-3.9.9\bin\mvn.cmd"`) which might not be suitable
        for all environments. This path should ideally be configurable.
        The Maven command execution has a timeout of 30 seconds.

    Args:
        group_id (str): The groupId of the dependency.
        artifact_id (str): The artifactId of the dependency.
        version (str | None): The version of the dependency. If None, considered unresolvable.
        classifier (str | None, optional): The classifier of the dependency. Defaults to None.
        dep_type (str, optional): The type of the dependency (e.g., "jar", "zip").
                                  Defaults to "jar".

    Returns:
        bool: True if the dependency is found locally or resolved successfully via Maven,
              False otherwise.
    """
    if not version:
        return False

    ext = dep_type if dep_type != "jar" else "jar"
    if classifier:
        artifact_name = f"{artifact_id}-{version}-{classifier}.{ext}"
    else:
        artifact_name = f"{artifact_id}-{version}.{ext}"
    m2_repo = os.path.expanduser("~/.m2/repository")
    group_path = os.path.join(m2_repo, *group_id.split('.'), artifact_id, version)
    artifact_path = os.path.join(group_path, artifact_name)
    if os.path.isfile(artifact_path):
        return True

    # If not found locally, try to resolve via Maven
    artifact_str = f"{group_id}:{artifact_id}:{version}"
    if classifier:
        artifact_str += f":{classifier}"
    if dep_type and dep_type != "jar":
        artifact_str += f"@{dep_type}"
    cmd = [
        r"C:\apps\apache-maven-3.9.9\bin\mvn.cmd", "dependency:get",
        f"-Dartifact={artifact_str}",
        "-q"
    ]
    try:
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=30)
        return result.returncode == 0
    except Exception as e:
        logger.error(f"Error running Maven for {artifact_str}: {e}")
        return False

def find_duplicate_dependencies(dependencies):
    """
    Finds duplicate dependencies within a list of dependencies.

    A duplicate is defined as having the same `groupId`, `artifactId`, `classifier`,
    and `type`. The `version` is not considered for identifying duplicates, meaning
    different versions of the same GAC-T (GroupId, ArtifactId, Classifier, Type)
    will flag the GAC-T as duplicated.

    Args:
        dependencies (list[tuple[str, str, str | None, str | None, str]]):
            A list of dependency tuples.

    Returns:
        list[str]: A list of strings, where each string represents a GAC-T that
                   was found to have multiple version entries in the input list.
                   Format: "groupId:artifactId[:classifier][:type]".
    """
    seen = set()
    duplicates = set()
    for group_id, artifact_id, version, classifier, dep_type in dependencies:
        key = (group_id, artifact_id, classifier, dep_type)
        if key in seen:
            duplicates.add(key)
        else:
            seen.add(key)
    return [f"{g}:{a}" + (f":{c}" if c else "") + (f":{t}" if t and t != "jar" else "") for g, a, c, t in duplicates]

def validate_pom_dependencies(pom_file_path, target_folder):
    """
    Validates dependencies declared in a single `pom.xml` file.

    This function performs several checks:
    1.  Parses all declared dependencies.
    2.  Checks for missing artifact JARs/files in the `target_folder` and local Maven repo.
    3.  Attempts to resolve each dependency via Maven to check for reachability.
    4.  Identifies duplicate dependency declarations (same GAC-T, different versions).

    Args:
        pom_file_path (str): The path to the `pom.xml` file.
        target_folder (str): The path to the project's target/build output directory.

    Returns:
        dict[str, list]: A dictionary containing the validation results:
            - "all_dependencies" (list[tuple]): List of all parsed dependency tuples.
            - "missing_jars" (list[str]): List of artifact names not found locally.
            - "unresolved_dependencies" (list[str]): List of dependency coordinates
              that could not be resolved via Maven.
            - "duplicate_dependencies" (list[str]): List of GAC-T strings for
              dependencies that have multiple version entries.
    """
    results = {
        "missing_jars": [],
        "unresolved_dependencies": [],
        "duplicate_dependencies": [],
        "all_dependencies": []
    }
    dependencies = parse_pom_dependencies(pom_file_path)
    results["all_dependencies"] = dependencies

    # Check for missing artifacts in target/lib and local m2 repo
    missing_jars = check_dependency_jars(target_folder, dependencies)
    results["missing_jars"] = missing_jars

    # Check for unresolved dependencies via Maven
    unresolved = []
    for group_id, artifact_id, version, classifier, dep_type in dependencies:
        if not check_dependency_resolution(group_id, artifact_id, version, classifier, dep_type):
            unresolved.append(
                f"{group_id}:{artifact_id}:{version}" +
                (f":{classifier}" if classifier else "") +
                (f":{dep_type}" if dep_type and dep_type != "jar" else "")
            )
    results["unresolved_dependencies"] = unresolved

    # Check for duplicates
    duplicates = find_duplicate_dependencies(dependencies)
    results["duplicate_dependencies"] = duplicates

    return results

def validate_all_projects(base_folder):
    """
    Validates the primary `pom.xml` file located directly within the `base_folder`.

    This function specifically targets the `pom.xml` at the root of `base_folder`
    and does not recurse into sub-modules or sub-directories. It orchestrates
    the dependency validation process for this single POM file.

    Args:
        base_folder (str): The path to the base directory of the MuleSoft project
                           (or a directory containing a `pom.xml` to be validated).

    Returns:
        dict[str, dict[str, list]]: A dictionary where the key is the path to the
        `pom.xml` file validated, and the value is a dictionary of results as
        returned by `validate_pom_dependencies`. If no `pom.xml` is found in
        `base_folder`, an empty dictionary is returned.
    """
    validation_report = {}
    pom_path = os.path.join(base_folder, "pom.xml")
    target_folder = os.path.join(base_folder, "target")
    if os.path.isfile(pom_path):
        logger.info(f"Validating dependencies for {pom_path}")
        result = validate_pom_dependencies(pom_path, target_folder)
        validation_report[pom_path] = result
    else:
        logger.warning(f"No pom.xml found in {base_folder}")
    return validation_report